# LLaMA Factory image for NVIDIA DGX-SPARK (ARM64 / Grace Blackwell).
# Build on DGX-SPARK or any linux/arm64 host:
#   docker build -f docker/docker-cuda/Dockerfile.dgx-spark -t llamafactory:dgx-spark .
# See: https://build.nvidia.com/spark/llama-factory

# NGC PyTorch container for Grace Blackwell (ARM64); supports CUDA 13
# https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch
ARG BASE_IMAGE=nvcr.io/nvidia/pytorch:25.11-py3
FROM ${BASE_IMAGE}

# Installation arguments
ARG PIP_INDEX=https://pypi.org/simple
ARG HTTP_PROXY=""

ENV DEBIAN_FRONTEND=noninteractive
ENV PIP_ROOT_USER_ACTION=ignore
ENV VLLM_WORKER_MULTIPROC_METHOD=spawn
ENV NODE_OPTIONS=""
ENV http_proxy="${HTTP_PROXY}"
ENV https_proxy="${HTTP_PROXY}"

SHELL ["/bin/bash", "-c"]
WORKDIR /app

# Use optional pip mirror
RUN pip config set global.index-url "${PIP_INDEX}" && \
    pip config set global.extra-index-url "${PIP_INDEX}" && \
    pip install --no-cache-dir --upgrade pip packaging wheel setuptools editables "hatchling>=1.18.0"

# Copy repo (build context = repository root)
COPY . /app

# Remove torchaudio from pyproject.toml so we install a version matching the container's PyTorch
RUN sed -i 's/"torchaudio[^"]*",\?//' pyproject.toml

# Install torchaudio matching container's PyTorch version and CUDA.
# NGC images may use 2.10.0a0; PyTorch index has 2.10.0, so strip alpha suffix.
# Detect CUDA version: if CUDA 13.x, use cu130 index; otherwise cu128.
# If installation fails (e.g. no matching wheel for ARM64), continue without torchaudio.
RUN TORCH_VER=$(python -c "import torch, re; v=torch.__version__.split('+')[0]; print(re.sub(r'[a-z]+\d*$', '', v))") && \
    CUDA_MAJOR=$(python -c "import torch; print(torch.version.cuda.split('.')[0])" 2>/dev/null || echo "12") && \
    if [ "${CUDA_MAJOR}" = "13" ]; then \
        TORCH_INDEX="https://download.pytorch.org/whl/cu130"; \
    else \
        TORCH_INDEX="https://download.pytorch.org/whl/cu128"; \
    fi && \
    pip install --no-cache-dir --no-deps "torchaudio==${TORCH_VER}" --index-url "${TORCH_INDEX}" || \
    echo "Warning: torchaudio installation failed (may not have ARM64 wheel for CUDA ${CUDA_MAJOR}). Audio features will be unavailable."

# Install LLaMA Factory and metrics/deepspeed (same as main Dockerfile)
RUN pip install --no-cache-dir --no-build-isolation -e . && \
    pip install --no-cache-dir --no-build-isolation -r requirements/metrics.txt -r requirements/deepspeed.txt || true

# Expose ports
ENV GRADIO_SERVER_PORT=7860
ENV API_PORT=8000
EXPOSE 7860 8000

# Unset proxy
ENV http_proxy=
ENV https_proxy=

RUN pip config unset global.index-url 2>/dev/null || true && \
    pip config unset global.extra-index-url 2>/dev/null || true

# Default: interactive shell (same as docker-compose for other images)
CMD ["bash"]
